---
title:      流计算框架
date:       2020-08-26
author:     XPX
catalog: true
tags:
    - 云计算
---

[TOC]

> 时下，对信息高时效性、可操作性的需求不断增长，这要求软件系统在更少的时间内能处理更多的数据。传统的大数据处理模型将在线事务处理和离线分析从时序上将两者完全分割开来，但显然该架构目前已经越来越落后于人们对于大数据实时处理的需求。 流计算的产生即来源于对于上述数据加工时效性的严苛需求:数据的业务价值随着时间的流失而迅速降低，因此在数据发生后必须尽快对其进行计算和处理。而传统的大数据处理模式对于数据加工均遵循传统日清日毕模式，即以小时甚至以天为计算周期对当前数据进行累计并处理，显然这类处理方式无法满足数据实时计算的需求。在诸如实时大数据分析、风控预警、实时预测、金融交易等诸多业务场景领域，批量(或者说离线)处理对于上述对于数据处理时延要求苛刻的应用领域而言是完全无法胜任其业务需求的。而流计算作为一类针对流数据的实时计算模型，可有效地缩短全链路数据流时延、实时化计算逻辑、平摊计算成本，最终有效满足实时处理大数据的业务需求。 



通常而言，流计算具备三大类特点：

- 实时(realtime)且无界(unbounded)的数据流。流计算面对计算的 是实时且流式的，流数据是按照时间发生顺序地被流计算订阅和消费。且由于数据发生的持续性，数据流将长久且持续地集成进入流计算系统。例如，对于网站的访问点击日志流，只要网站不关闭其点击日志流将一直不停产生并进入流计算系统。因此，对于流系统而言，数据是实时且不终止(无界)的。
- 持续(continuos)且高效的计算。流计算是一种”事件触发”的计算模式，触发源就是上述的无界流式数据。一旦有新的流数据进入流计算，流计算立刻发起并进行一次计算任务，因此整个流计算是持续进行的计算。
- 流式(streaming)且实时的数据集成。流数据触发一次流计算的计算结果，可以被直接写入目的数据存储，例如将计算后的报表数据直接写入RDS进行报表展示。因此流数据的计算结果可以类似流式数据一样持续写入目的数据存储。

明确了流处理概念的同时，一些其他的概念也需要了解：

- 离线计算
- 批处理计算与流式/实时计算。

# 离线计算框架

离线计算就是在计算开始前已知所有输入数据，输入数据不会产生变化，且在解决一个问题后就要立即得出结果的前提下进行的计算。在大数据中属于数据的计算部分，在该部分中与离线计算对应的则是实时计算。一般来说，离线计算具有数据量巨大且保存时间长；在大量数据上进行复杂的批量运算；数据在计算之前已经完全到位，不会发生变化；能够方便的查询批量计算的结果等特点。

常用的离线计算框架包括有：

- Hadoop，适用于离线大批量数据处理，不需要多次迭代。

  - MapReduce，Hadoop框架最核心的设计就是HDFS和MapReduce。HDFS为海量的数据提供了存储，MapReduce则为海量的数据提供了计算，它适用于大规模数据集的并行运算。 
  - HDFS，这个Hadoop分布式文件系统能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。

- Spark，适用于离线快速的处理，不能用于处理需要长期保存的数据；适用于多次迭代的计算模型。

  

## Hadoop

Hadoop是一个由Apache基金会所开发的[分布式系统](https://baike.baidu.com/item/分布式系统/4905336)基础架构。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。Hadoop实现了一个[分布式文件系统](https://baike.baidu.com/item/分布式文件系统/1250388)（Hadoop Distributed File System），简称HDFS。HDFS有高[容错性](https://baike.baidu.com/item/容错性/9131391)的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问[应用程序](https://baike.baidu.com/item/应用程序/5985445)的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。Hadoop的框架最核心的设计就是：[HDFS](https://baike.baidu.com/item/HDFS/4836121)和[MapReduce](https://baike.baidu.com/item/MapReduce/133425)。HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算

### 分布式系统（distributed system）

分布式系统（distributed system）是建立在**网络**之上的软件系统。是因为软件的特性，所以分布式系统具有高度的**内聚性**和**透明性**。内聚性是指每一个数据库分布节点高度自治，有本地的数据库管理系统。透明性是指每一个数据库分布节点对用户的应用来说都是透明的，看不出是本地还是远程。在分布式数据库系统中，用户感觉不到数据是分布的，即用户不须知道关系是否分割、有无副本、数据存于哪个站点以及事务在哪个站点上执行等。

#### 内聚性

内聚性是一软件度量，是指机能相关的程序组合成一模块的程度，或是各机能凝聚的状态或程度。是结构化分析的重要概念之一。内聚性和耦合性是一个相对的概念。

内聚性从低到高排列为：

1. 偶然内聚性：偶然内聚性是指模块中的机能只是刚好放在一起，模块中各机能之间唯一的关系是其位置在同一个模块中（例如：“工具”模块）。
2. 逻辑内聚性：逻辑内聚性是只要机能在逻辑上分为同一类，不论各机能的本质是否有很大差异，就将这些机能放在同一模块中（例如将所有的鼠标和键盘都放在输入处理副程序中）。模块内执行几个逻辑上相似的功能，通过参数确定该模块完成哪一个功能。
3. 时间内聚性：时间内聚性是指将相近时间点运行的程序，放在同一个模块中（例如在捕捉到一个异常后调用一函数，在函数中关闭已打开的文件、产生错误日志、并告知用户）。
4. 程序内聚性：程序内聚性是指依一组会按照固定顺序运行的程序放在同一个模块中（例如一个函数检查文件的权限，之后打开文件）。
5. 联系内聚性/信息内聚/通信内聚：联系内聚性是指模块中的机能因为处理相同的数据或者指各处理使用相同的输入数据或者产生相同的输出数据，所以放在同一个模块中（例如一个模块中的许多机能都访问同一个记录）。
6. 依序内聚性/顺序内聚：依序内聚性是指模块中的各机能彼此的输入及输出数据相关，一模块的输出数据是另一个模块的输入，类似工厂的生产线（例如一个模块先读取文件中的数据，之后再处理数据）。
7. 功能内聚性：功能内聚性是指模块中的各机能是因为它们都对模块中单一明确定义的任务有贡献（例如XML字符串的词法分析）。

研究提出*偶然内聚性和逻辑内聚性是不好的，联系内聚性和依序内聚性是好的，而功能内聚性是最理想的状态。* 

### MapReduce

MapReduce是面向大数据并行处理的计算模型、框架和平台，它隐含了以下三层含义：

1. MapReduce是一个**基于集群的高性能并行计算平台**（Cluster Infrastructure）。它允许用市场上普通的商用服务器构成一个包含数十、数百至数千个节点的分布和并行计算集群。

2. MapReduce是一个**并行计算与运行软件框架**（Software Framework）。它提供了一个庞大但设计精良的并行计算软件框架，能自动完成计算任务的并行化处理，自动划分计算数据和计算任务，在集群节点上自动分配和执行任务以及收集计算结果，将数据分布存储、数据通信、容错处理等并行计算涉及到的很多系统底层的复杂细节交由系统负责处理，大大减少了软件开发人员的负担。

3. MapReduce是一个**并行程序设计模型与方法**（Programming Model & Methodology）。它借助于函数式程序设计语言Lisp的设计思想，提供了一种简便的并行程序设计方法，用Map和Reduce两个函数编程实现基本的并行计算任务，提供了抽象的操作和并行编程接口，以简单方便地完成大规模数据的编程和计算处理 。



> 参考资料：
>
> [大数据之MapReduce详解](https://zhuanlan.zhihu.com/p/82399103)

### HDFS(Hadoop Distributed File System)

首先，它是一个文件系统，用于存储文件，通过统一的命名空间——目录树来定位文件。其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色；

#### HDFS特性

1. HDFS中的文件在物理上是**分块存储（block）**，块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在hadoop2.x版本中是128M，老版本中是64M
2. HDFS文件系统会给客户端提供一个**统一的抽象目录树**，客户端通过路径来访问文件，形如：hdfs://namenode:port/dir-a/dir-b/dir-c/file.data
3. **目录结构及文件分块信息****(元数据)**的管理由namenode节点承担——namenode是HDFS集群主节点，负责维护整个hdfs文件系统的目录树，以及每一个路径（文件）所对应的block块信息（block的id，及所在的datanode服务器）
4. 文件的各个block的存储管理由datanode节点承担--- datanode是HDFS集群从节点，每一个block都可以在多个datanode上存储多个副本
5. HDFS是设计成适应一次写入，多次读出的场景，且不支持文件的修改

*(注：适合用来做数据分析，并不适合用来做网盘应用，因为，不便修改，延迟大，网络开销大，成本太高)*

#### 优点

1、可构建在廉价机器上

　　　　通过多副本提高可靠性，提供了容错和恢复机制

　　　　服务器节点的宕机是常态  必须理性对象

2、高容错性

　　　　数据自动保存多个副本，副本丢失后，自动恢复

　　　　**HDFS的核心设计思想： 分散均匀存储 + 备份冗余存储**

3、适合批处理

　　　　移动计算而非数据，数据位置暴露给计算框架

　　　　海量数据的计算 任务 最终是一定要被切分成很多的小任务进行

4、适合大数据处理

　　　　GB、TB、甚至 PB 级数据，百万规模以上的文件数量，10K+节点规模

5、流式文件访问

　　　　 一次性写入，多次读取，保证数据一致性

#### 缺点

1、低延迟数据访问

　　　　比如毫秒级 低延迟与高吞吐率

2、小文件存取

　　　　占用 NameNode 大量内存 150b* 1000W = 15E,1.5G 寻道时间超过读取时间

3、并发写入、文件随机修改

　　　　一个文件只能有一个写者 仅支持 append

>  参考资料：
>
> [[Hadoop学习之路（六）HDFS基础](https://www.cnblogs.com/qingyunzong/p/8524594.html)](https://www.cnblogs.com/qingyunzong/p/8524594.html)
>
> [Hadoop学习之路（九）HDFS深入理解](https://www.cnblogs.com/qingyunzong/p/8535995.html)

## Spark

Apache Spark 是专为大规模数据处理而设计的快速通用的计算引擎。Spark是UC Berkeley AMP lab (加州大学伯克利分校的AMP实验室)所开源的类Hadoop MapReduce的通用并行框架，Spark，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是——Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的MapReduce的算法。

#### 特性

1. 高效性

   运行速度提高100倍。

   Apache Spark使用最先进的DAG调度程序，查询优化程序和物理执行引擎，实现批量和流式数据的高性能。

2. 易用性

   Spark支持Java、Python和Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的shell，可以非常方便地在这些shell中使用Spark集群来验证解决问题的方法。

3. 通用性

   Spark提供了统一的解决方案。Spark可以用于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝使用。Spark统一的解决方案非常具有吸引力，毕竟任何公司都想用统一的平台去处理遇到的问题，减少开发和维护的人力成本和部署平台的物力成本。

4. 兼容性

   Spark可以非常方便地与其他的开源产品进行融合。比如，Spark可以使用Hadoop的YARN和Apache Mesos作为它的资源管理和调度器，器，并且可以处理所有Hadoop支持的数据，包括HDFS、HBase和Cassandra等。这对于已经部署Hadoop集群的用户特别重要，因为不需要做任何数据迁移就可以使用Spark的强大处理能力。Spark也可以不依赖于第三方的资源管理和调度器，它实现了Standalone作为其内置的资源管理和调度框架，这样进一步降低了Spark的使用门槛，使得所有人都可以非常容易地部署和使用Spark。此外，Spark还提供了在EC2上部署Standalone的Spark集群的工具。

# 批处理计算与流式计算

大数据的计算模式主要分为批量计算(batch computing)、流式计算(stream computing)、交互计算(interactive computing)、图计算(graph computing)等。其中，流式计算和批量计算是两种主要的大数据计算模式，分别适用于不同的大数据应用场景。

流数据（或数据流）是<u>指在时间分布和数量上无限的一系列动态数据集合体</u>，数据的价值随着时间的流逝而降低，因此必须实时计算给出秒级响应。流式计算，顾名思义，就是<u>对数据流进行处理，是实时计算</u>。批量计算则统一收集数据，存储到数据库中，然后对<u>数据进行批量处理的数据计算方式</u>。主要体现在以下几个方面：

1. 数据时效性不同：流式计算实时、低延迟， 批量计算非实时、高延迟。

2. 数据特征不同：流式计算的数据一般是动态的、没有边界的，而批处理的数据一般则是静态数据。

3. 应用场景不同：流式计算应用在实时场景，时效性要求比较高的场景，如实时推荐、业务监控...批量计算一般说批处理，应用在实时性要求不高、离线计算的场景下，数据分析、离线报表等。

4. 运行方式不同，流式计算的任务持续进行的，批量计算的任务则一次性完成。

传统的数据融合通常基于批模式。在批的模式下，我们会通过一些周期性运行的ETL JOB，将数据从关系型数据库、文件存储向下游的目标数据库进行同步，中间可能有各种类型的转换。另一种是Data Pipeline模式。与批模式相比相比， 其最核心的区别是将批量变为实时：输入的数据不再是周期性的去获取，而是源源不断的来自于数据库的日志、消息队列的消息。进而通过一个实时计算引擎，进行各种聚合运算，产生输出结果，并且写入下游。现代的一些处理框架，包括Flink、Kafka Streams、Spark，或多或少都能够支持批和流两种概念。



>  参考资料：
>
> https://www.zhihu.com/question/313869609/answer/829714737

# 流式计算框架

## Storm

Storm是一个分布式的、容错的实时计算系统，做作为最早的一个实时计算框架，早期应用于各大互联网公司。在Storm出现之前，进行实时处理是非常痛苦的事情，我们主要的时间都花在关注往哪里发消息，从哪里接收消息，消息如何序列化，真正的业务逻辑只占了源代码的一小部分。一个应用程序的逻辑运行在很多worker上，但这些worker需要各自单独部署，还需要部署消息队列。最大问题是系统很脆弱，而且不是容错的：需要自己保证消息队列和worker进程工作正常。Storm具有编程简单、高性能，低延迟、分布式、可扩展、容错、消息不丢失等特点。

在Storm中，需要先设计一个实时计算结构，我们称之为拓扑（topology）。之后，这个拓扑结构会被提交给集群，其中主节点（master node）负责给工作节点（worker node）分配代码，工作节点负责执行代码。在一个拓扑结构中，包含spout和bolt两种角色。数据在spouts之间传递，这些spouts将数据流以tuple元组的形式发送；而bolt则负责转换数据流。

但是，Storm没有提供exactly once的功能，并且开启ack功能后又会严重影响吞吐，所以会给大家一种印象：流式系统只适合吞吐相对较小的、低延迟不精确的计算；而精确的计算则需要由批处理系统来完成，所以出现了Lambda架构，同时运行两个系统：一个流式，一个批量，用批量计算的精确性来弥补流式计算的不足，但是这个架构存在一个问题就是需要同时维护两套系统，代价比较大。

![img](https://xpx-picbed.oss-cn-beijing.aliyuncs.com//blog/2020/08/285763-20200401104635916-53280498.jpg)

## Apache Spark

Spark Streaming，即核心Spark API的扩展，不像Storm那样一次处理一个数据流。相反，它在处理数据流之前，会按照时间间隔对数据流进行分段切分。Spark针对连续数据流的抽象，我们称为DStream（Discretized Stream）。 DStream是小批处理的RDD（弹性分布式数据集）， RDD则是分布式数据集，可以通过任意函数和滑动数据窗口（窗口计算）进行转换，实现并行操作。

Spark streaming采用小批量的方式，提高了吞吐性能。Spark streaming批量读取数据源中的数据，然后把每个batch转化成内部的RDD。Spark streaming以batch为单位进行计算），而不是以record为单位，大大减少了ack所需的开销，显著满足了高吞吐、低延迟的要求，同时也提供exactly once功能。但也因为处理数据的粒度变大，导致Spark streaming的数据延时不如Storm，Spark streaming是秒级返回结果（与设置的batch间隔有关），Storm则是毫秒级。

![img](https://xpx-picbed.oss-cn-beijing.aliyuncs.com//blog/2020/08/285763-20200401104643822-1547991446.jpg)

## Apache Flink

针对流数据+批数据的计算框架。Flink把批数据看作流数据的一种特例，延迟性较低(毫秒级)，且能够保证消息传输不丢失不重复。

Flink创造性地统一了流处理和批处理，作为流处理看待时输入数据流是无界的，而批处理被作为一种特殊的流处理，只是它的输入数据流被定义为有界的。Flink程序由Stream和Transformation这两个基本构建块组成，其中Stream是一个中间结果数据，而Transformation是一个操作，它对一个或多个输入Stream进行计算处理，输出一个或多个结果Stream。

Flink是一个针对流数据和批数据的分布式处理引擎，主要由Java代码实现。对 Flink 而言，其所要处理的主要场景就是流数据，批数据只是流数据的一个极限特例而已。Flink 可以支持本地的快速迭代，以及一些环形的迭代任务，并且可以定制化内存管理。在这点，如果要对比 Flink 和 Spark 的话，Flink 并没有将内存完全交给应用层。这也是为什么 Spark 相对于 Flink，更容易出现 OOM 的原因（out of memory）。就框架本身与应用场景来说，Flink 更相似与 Storm。

Apache Flink的特点有：低延迟的流处理器；丰富的API能够帮助程序员快速开发流数据应用；灵活的操作状态和流窗口；高效的流与数据的容错。

![img](https://xpx-picbed.oss-cn-beijing.aliyuncs.com//blog/2020/08/285763-20200401104651218-1558444835.jpg)

## Kafka

Kafka 是由 Linkedin公司开发的，它是一个分布式的，支持多分区、多副本，基于 Zookeeper 的分布式消息流平台，它同时也是一款开源的**基于发布订阅模式的消息引擎系统**。

### 特性

1. 高吞吐、低延迟：kakfa 最大的特点就是收发消息非常快，kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒。
2. 高伸缩性： 每个主题(topic) 包含多个分区(partition)，主题中的分区可以分布在不同的主机(broker)中。
3. 持久性、可靠性： Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，Zookeeper 我们知道它的数据能够持久存储。
4. 容错性： 允许集群中的节点失败，某个节点宕机，Kafka 集群能够正常工作
5. 高并发： 支持数千个客户端同时读写

![img](https://xpx-picbed.oss-cn-beijing.aliyuncs.com//blog/2020/08/16eb068cc433bb21)

如上图所示，一个典型的 Kafka 集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。





> 参考资料：
>
> https://www.cnblogs.com/duanxz/p/12610999.html
>
> https://juejin.im/post/6844903495670169607
>
> https://cloud.tencent.com/developer/article/1039811